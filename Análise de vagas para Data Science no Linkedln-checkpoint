{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f0ead44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5ff57537",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(r\"C:\\Users\\saull\\Documents\\Planilhas power bi\\Linkedln\\job_postings.csv\")\n",
    "df2 = pd.read_csv(r\"C:\\Users\\saull\\Documents\\Planilhas power bi\\Linkedln\\job_skills.csv\")\n",
    "df3 = pd.read_csv(r\"C:\\Users\\saull\\Documents\\Planilhas power bi\\Linkedln\\job_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f0b74dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df1, df2, on='job_link')\n",
    "df = pd.merge(df, df3, on='job_link')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4fffce",
   "metadata": {},
   "source": [
    "## Check básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "69f6b15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_link               0\n",
       "last_processed_time    0\n",
       "last_status            0\n",
       "got_summary            0\n",
       "got_ner                0\n",
       "is_being_worked        0\n",
       "job_title              0\n",
       "company                0\n",
       "job_location           1\n",
       "first_seen             0\n",
       "search_city            0\n",
       "search_country         0\n",
       "search_position        0\n",
       "job_level              0\n",
       "job_type               0\n",
       "job_skills             5\n",
       "job_summary            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6e54ed7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12211 entries, 0 to 12216\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   job_link             12211 non-null  object\n",
      " 1   last_processed_time  12211 non-null  object\n",
      " 2   last_status          12211 non-null  object\n",
      " 3   got_summary          12211 non-null  object\n",
      " 4   got_ner              12211 non-null  object\n",
      " 5   is_being_worked      12211 non-null  object\n",
      " 6   job_title            12211 non-null  object\n",
      " 7   company              12211 non-null  object\n",
      " 8   job_location         12211 non-null  object\n",
      " 9   first_seen           12211 non-null  object\n",
      " 10  search_city          12211 non-null  object\n",
      " 11  search_country       12211 non-null  object\n",
      " 12  search_position      12211 non-null  object\n",
      " 13  job_level            12211 non-null  object\n",
      " 14  job_type             12211 non-null  object\n",
      " 15  job_skills           12211 non-null  object\n",
      " 16  job_summary          12211 non-null  object\n",
      "dtypes: object(17)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9299efb5",
   "metadata": {},
   "source": [
    "## Tratamento e limpeza dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0c23c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Num_de_skills'] = df['job_skills'].str.split(', ').apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cd4be77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills = ''\n",
    "for skill in df.job_skills:\n",
    "    skills += skill.capitalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "91ce5a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine learning',\n",
       " 'programming',\n",
       " 'python',\n",
       " 'scala',\n",
       " 'java',\n",
       " 'data engineering',\n",
       " 'distributed computing',\n",
       " 'statistical modeling',\n",
       " 'optimization',\n",
       " 'data pipelines']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = skills.split(', ')\n",
    "skills[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "da5d1815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('python', 4399), ('sql', 4219), ('communication', 2428)]\n"
     ]
    }
   ],
   "source": [
    "# Dividir o texto em palavras e contar a frequência de cada palavra em todas as linhas\n",
    "contador_palavras = {}\n",
    "\n",
    "# Dividindo \n",
    "for palavra in skills:\n",
    "        contador_palavras[palavra] = contador_palavras.get(palavra, 0) + 1\n",
    "\n",
    "# Obter as 3 palavras mais comuns em todas as linhas do DataFrame\n",
    "mais_comuns = sorted(contador_palavras.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "print(mais_comuns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b38efd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3000 = counts.most_common(3000)\n",
    "c3000 = Counter(dict(top_2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3c0a6776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'python3'] 2\n",
      "['sql', 'tsql'] 2\n",
      "['communication', 'communications'] 2\n",
      "['data analysis', 'data analytics', 'data analyst'] 3\n",
      "['data visualization', 'data visualizations', 'data visualisation'] 3\n",
      "['machine learning', 'machine learning (ml)'] 2\n",
      "['communication skills', 'verbal communication skills', 'strong communication skills'] 3\n",
      "['project management', 'product management', 'agile project management'] 3\n",
      "['data modeling', 'data modelling', 'data model'] 3\n",
      "['problem solving', 'problemsolving'] 2\n",
      "['data warehousing', 'data warehouse'] 2\n",
      "['data management', 'metadata management', 'database management'] 3\n",
      "['analytical skills', 'analytic skills'] 2\n",
      "['teamwork', 'team work'] 2\n",
      "['data engineering', 'data engineer', 'database engineering'] 3\n",
      "['power bi', 'powerbi'] 2\n",
      "['business intelligence', 'business intelligence (bi)', 'business intelligence tools'] 3\n",
      "['statistics', 'biostatistics'] 2\n",
      "['data integration', 'data migration', 'data interpretation'] 3\n",
      "[\"bachelor's degree\", 'bachelors degree', 'bachelor’s degree'] 3\n",
      "['data pipelines', 'data pipeline'] 2\n",
      "['data security', 'database security'] 2\n",
      "['time management', 'team management', 'tape management'] 3\n",
      "['data architecture', 'data architectures', 'data architect'] 3\n",
      "['artificial intelligence', 'artificial intelligence (ai)'] 2\n",
      "['statistical analysis', 'statistical analyses'] 2\n",
      "['software development', 'agile software development'] 2\n",
      "['databricks', 'data bricks'] 2\n",
      "['organizational skills', 'organization skills'] 2\n",
      "['problemsolving skills', 'problem solving skills'] 2\n",
      "['data transformation', 'digital transformation'] 2\n",
      "['agile development', 'api development', 'mobile development'] 3\n",
      "['written communication', 'written communication skills'] 2\n",
      "['sas', 'ssas', 'saas'] 3\n",
      "['risk management', 'task management'] 2\n",
      "['sql server', 'ms sql server'] 2\n",
      "['databases', 'database'] 2\n",
      "['data processing', 'data preprocessing', 'big data processing'] 3\n",
      "['quality control', 'data quality control'] 2\n",
      "['natural language processing', 'natural language processing (nlp)'] 2\n",
      "['statistical modeling', 'statistical modelling', 'statistical models'] 3\n",
      "['relational databases', 'relational database', 'nonrelational databases'] 3\n",
      "['data cleansing', 'data cleaning'] 2\n",
      "['verbal communication', 'oral communication', 'verbal communication skills'] 3\n",
      "['business analysis', 'business analytics', 'business analyst'] 3\n",
      "['data validation', 'data evaluation'] 2\n",
      "[\"master's degree\", 'masters degree'] 2\n",
      "['scikitlearn', 'scikit learn'] 2\n",
      "['data structures', 'data structure', 'database structures'] 3\n",
      "['stakeholder management', 'stakeholder engagement'] 2\n",
      "['change management', 'case management'] 2\n",
      "['programming', 'r programming'] 2\n",
      "['quality assurance', 'data quality assurance'] 2\n",
      "['distributed systems', 'distributed file systems'] 2\n",
      "['data storage', 'data stores', 'datastage'] 3\n",
      "['security', 'security+'] 2\n",
      "['shell scripting', 'unix shell scripting', 'sql scripting'] 3\n",
      "['postgresql', 'postgres'] 2\n",
      "['decision making', 'decisionmaking'] 2\n",
      "['agile methodologies', 'agile methodology'] 2\n",
      "['rdbms', 'dbms'] 2\n",
      "['performance tuning', 'performance testing'] 2\n",
      "['data entry', 'data center'] 2\n",
      "['big data technologies', 'data technologies'] 2\n",
      "['data lakes', 'data lake'] 2\n",
      "['predictive modeling', 'predictive models'] 2\n",
      "['economics', 'econometrics'] 2\n",
      "['dashboards', 'dashboard'] 2\n",
      "['database administration', 'data administration'] 2\n",
      "['google cloud platform', 'google cloud platform (gcp)'] 2\n",
      "['cybersecurity', 'cyber security'] 2\n",
      "['nosql databases', 'sql databases'] 2\n",
      "['informatica', 'informatics'] 2\n",
      "['predictive analytics', 'predictive analysis', 'prescriptive analytics'] 3\n",
      "['presentation', 'presentations'] 2\n",
      "['chemistry', 'biochemistry'] 2\n",
      "['data models', 'data model'] 2\n",
      "['llms', 'llm'] 2\n",
      "['programming languages', 'r (programming language)'] 2\n",
      "['mlops', 'ml ops'] 2\n",
      "['sap', 'soap'] 2\n",
      "['pl/sql', 'plsql'] 2\n",
      "['data warehouses', 'data warehouse'] 2\n",
      "['datadriven decision making', 'datadriven decisionmaking'] 2\n",
      "['statistical methods', 'statistical models'] 2\n",
      "['requirements gathering', 'requirement gathering'] 2\n",
      "['master data management', 'master data management (mdm)'] 2\n",
      "['root cause analysis', 'rootcause analysis'] 2\n",
      "['data quality management', 'quality management'] 2\n",
      "['vendor management', 'inventory management'] 2\n",
      "['lambda', 'lambdas'] 2\n",
      "['etl pipelines', 'etl pipeline'] 2\n",
      "['data strategy', 'data strategies'] 2\n",
      "['cloud services', 'aws cloud services'] 2\n",
      "['quantitative analysis', 'qualitative analysis'] 2\n",
      "['data infrastructure', 'it infrastructure'] 2\n",
      "['data presentation', 'data representation'] 2\n",
      "['confidentiality', 'data confidentiality'] 2\n",
      "['visualization', 'visualizations', 'virtualization'] 3\n",
      "['apis', 'api'] 2\n",
      "['people management', 'problem management'] 2\n",
      "['cisa', 'cia'] 2\n",
      "['cloud platforms', 'cloud platform'] 2\n",
      "['healthcare', 'health care'] 2\n",
      "['ascp certification', 'aws certification', 'mlt ascp certification'] 3\n",
      "['risk assessment', 'risk assessments'] 2\n",
      "['amazon web services', 'amazon web services (aws)'] 2\n",
      "['database development', 'data development'] 2\n",
      "['bigquery', 'big query'] 2\n",
      "['medical technology', 'medical technologist', 'medical terminology'] 3\n",
      "['data standardization', 'standardization'] 2\n",
      "['model evaluation', 'model validation'] 2\n",
      "['vision', 'visio'] 2\n",
      "['cloud technologies', 'cloud technology'] 2\n",
      "['azure databricks', 'azure data bricks'] 2\n",
      "['elasticsearch', 'elastic search'] 2\n",
      "['systems engineering', 'system engineering'] 2\n",
      "['data visualization tools', 'visualization tools', 'data visualizations'] 3\n",
      "['detailoriented', 'detail oriented'] 2\n",
      "['system design', 'systems design'] 2\n",
      "['code reviews', 'code review'] 2\n",
      "['data platforms', 'data platform', 'big data platforms'] 3\n",
      "['model development', 'etl development', 'mobile development'] 3\n",
      "['sparql', 'sparksql'] 2\n",
      "['mechanical engineering', 'chemical engineering'] 2\n",
      "['cloud infrastructure', 'cloudbased infrastructure'] 2\n",
      "['clinical laboratory science', 'clinical laboratory scientist', 'medical laboratory science'] 3\n",
      "['construction management', 'contract management'] 2\n",
      "['rdf', 'rdfs'] 2\n",
      "['supervised learning', 'unsupervised learning', 'service learning'] 3\n",
      "['experimental design', 'experiment design'] 2\n",
      "['cabling', 'scaling'] 2\n",
      "['system administration', 'systems administration'] 2\n",
      "['crm', 'crcm'] 2\n",
      "['rds', 'rdfs'] 2\n",
      "['database architecture', 'data architecture', 'data architectures'] 3\n",
      "['networks', 'network'] 2\n",
      "['infrastructure', 'it infrastructure'] 2\n",
      "['teaching', 'reaching'] 2\n",
      "['automated testing', 'automation testing'] 2\n",
      "['servicenow', 'service now'] 2\n",
      "['data dictionaries', 'data dictionary'] 2\n",
      "['structured data', 'unstructured data'] 2\n",
      "[\"bachelor's degree in computer science\", \"bachelor's in computer science\"] 2\n",
      "['dimensional data modeling', 'dimensional modeling'] 2\n",
      "['infrastructure as code', 'infrastructure as code (iac)'] 2\n",
      "['bioinformatics', 'informatics'] 2\n",
      "['data catalog', 'data cataloging'] 2\n",
      "['data flows', 'data flow', 'dataflow'] 3\n",
      "['database maintenance', 'data maintenance'] 2\n",
      "['clia', 'cia'] 2\n",
      "['data sources', 'data stores'] 2\n",
      "['sparkstreaming', 'spark streaming'] 2\n",
      "['angular js', 'angularjs'] 2\n",
      "['spreadsheets', 'spreadsheet'] 2\n",
      "['ccpa', 'cpa'] 2\n",
      "['incident management', 'client management'] 2\n",
      "['data replication', 'data deduplication'] 2\n",
      "['pair programming', 'r programming'] 2\n",
      "['software development life cycle', 'software development lifecycle'] 2\n",
      "['symantec data loss prevention (dlp)', 'data loss prevention (dlp)'] 2\n",
      "['dashboarding', 'dashboard'] 2\n",
      "['ml systems', 'crm systems'] 2\n",
      "['us citizenship', 'u.s. citizenship'] 2\n",
      "['data organization', 'data normalization'] 2\n",
      "['database performance tuning', 'database performance'] 2\n",
      "['data optimization', 'database optimization'] 2\n",
      "['system integration', 'systems integration'] 2\n",
      "['productivity', 'proactivity'] 2\n",
      "['security clearance', 'secret clearance'] 2\n",
      "['systems analysis', 'system analysis'] 2\n",
      "['rest api', 'rest apis'] 2\n",
      "['blood bank', 'blood banking'] 2\n",
      "[\"associate's degree\", 'associates degree', 'associate degree'] 3\n",
      "['highperformance computing', 'high performance computing'] 2\n",
      "['user experience', 'customer experience'] 2\n",
      "['database technologies', 'data technologies'] 2\n",
      "['process management', 'stress management'] 2\n",
      "['investigation', 'investigations'] 2\n",
      "['data systems', 'database systems'] 2\n",
      "['agile engineering', 'value engineering'] 2\n",
      "['business objects', 'business objectives', 'sap business objects'] 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frameworks', 'ml frameworks'] 2\n",
      "['analytical tools', 'analytics tools'] 2\n",
      "['machine learning models', 'machine learning (ml)'] 2\n",
      "['multicloud environments', 'cloud environments', 'cloud environment'] 3\n",
      "['data centers', 'data center'] 2\n",
      "['preventive maintenance', 'preventative maintenance', 'predictive maintenance'] 3\n",
      "['detail orientation', 'detailorientation'] 2\n",
      "['data marts', 'data mart'] 2\n",
      "['product documentation', 'process documentation'] 2\n",
      "['web development', 'etl development'] 2\n",
      "['kpis', 'kpi'] 2\n",
      "['cable management', 'case management'] 2\n",
      "['sql developer', 'sql development'] 2\n",
      "['angular', 'angularjs'] 2\n",
      "['data virtualization', 'data visualization', 'data visualizations'] 3\n",
      "['node.js', 'nodejs'] 2\n",
      "['database management systems', 'data management systems'] 2\n",
      "['audit', 'audits'] 2\n",
      "['asset management', 'case management'] 2\n",
      "['cloudbased data warehousing', 'cloudbased data warehousing services'] 2\n",
      "['spark sql', 'sparksql'] 2\n",
      "['cloud based data warehousing services', 'cloudbased data warehousing services'] 2\n",
      "['customer relationship management', 'customer relationship management (crm)'] 2\n",
      "['workload management', 'workflow management'] 2\n",
      "['data scientist', 'data scientists'] 2\n",
      "['jupyter notebook', 'jupyter notebooks'] 2\n",
      "['certifications', 'certification'] 2\n",
      "['medical laboratory scientist', 'medical laboratory scientist (mls)', 'medical laboratory science'] 3\n",
      "['competitive salary', 'competitive salaries'] 2\n",
      "['analytical models', 'analytical methods'] 2\n",
      "['data lifecycle management', 'product lifecycle management'] 2\n",
      "['relationship management', 'client relationship management'] 2\n",
      "['backup', 'backups'] 2\n",
      "['testdriven development', 'test driven development'] 2\n",
      "['cloud solutions', 'cloudbased solutions'] 2\n",
      "['applications', 'web applications'] 2\n",
      "['restful apis', 'restful api', 'rest apis'] 3\n",
      "['epic clarity data model certification', 'epic clinical data model certification'] 2\n",
      "['pmp certification', 'amt certification', 'certification'] 3\n",
      "['verbal and written communication', 'verbal and written communication skills'] 2\n",
      "['hadoop ecosystems', 'hadoop ecosystem'] 2\n",
      "['analytic methods', 'analytical methods'] 2\n",
      "['power apps', 'powerapps'] 2\n",
      "['dod secret clearance', 'top secret clearance', 'secret clearance'] 3\n",
      "['distributed database systems', 'distributed databases'] 2\n",
      "['antimoney laundering', 'antimoney laundering (aml)'] 2\n",
      "['yaml', 'aml'] 2\n",
      "['big data analytics', 'data analytics'] 2\n",
      "['python (programming language)', 'r (programming language)'] 2\n",
      "['ontology', 'oncology'] 2\n",
      "['full stack development', 'fullstack development'] 2\n",
      "['cost management', 'case management'] 2\n",
      "['agile scrum', 'agile/scrum'] 2\n",
      "['data monitoring', 'database monitoring'] 2\n",
      "['large datasets', 'large data sets'] 2\n",
      "['aab certification', 'aws certification', 'amt certification'] 3\n",
      "['subcontractor management', 'contract management'] 2\n",
      "['mssql', 'ms sql'] 2\n",
      "['hew certification', 'aws certification', 'certification'] 3\n",
      "['graduate degree', 'undergraduate degree'] 2\n",
      "['data pipelining', 'data pipeline'] 2\n",
      "['distributed data', 'distributed databases'] 2\n",
      "['data operations', 'database operations'] 2\n",
      "['telecommunications', 'communications'] 2\n",
      "['sql programming', 'r programming'] 2\n",
      "['database migration', 'data migration'] 2\n",
      "['logical data models', 'logical data modeling'] 2\n",
      "['data streams', 'data stores'] 2\n",
      "['technical training', 'technical writing'] 2\n",
      "['relational database design', 'relational databases'] 2\n",
      "['transformation', 'transportation'] 2\n",
      "['cams certification', 'aws certification', 'amt certification'] 3\n",
      "['data loss prevention', 'data loss prevention (dlp)'] 2\n",
      "['ftp', 'sftp'] 2\n",
      "['etl frameworks', 'ml frameworks'] 2\n",
      "['storage management', 'stress management'] 2\n",
      "['database structure', 'database structures', 'data structure'] 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1727"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from difflib import SequenceMatcher, get_close_matches\n",
    "\n",
    "# Função para mesclar rótulos semelhantes\n",
    "def merge_similar_labels(c3000):\n",
    "    conte_mescla = {}  # Contagens mescladas\n",
    "    mescla = set()  # Rótulos mesclados\n",
    "\n",
    "    for label, count in c3000.items():  # Para cada rótulo e sua contagem no dicionário c3000\n",
    "        if label in mescla:  # Se o rótulo já foi mesclado\n",
    "            continue  # Pula se já foi mesclado\n",
    "\n",
    "        # Encontre os rótulos mais semelhantes ao rótulo atual com uma similaridade maior que 90%\n",
    "        similar_labels = get_close_matches(label, c3000.keys(), cutoff=0.85)\n",
    "\n",
    "        # Escolha o rótulo mais apropriado entre os rótulos semelhantes (o mais longo)\n",
    "        chosen_label = min(similar_labels, key=len)\n",
    "\n",
    "        # Some as contagens dos rótulos semelhantes e atribua-os ao rótulo escolhido\n",
    "        conte_mescla[chosen_label] = sum(c3000[l] for l in similar_labels)\n",
    "        if (len(list(l for l in similar_labels)) > 1):\n",
    "            print(list(l for l in similar_labels), len(list(l for l in similar_labels)))\n",
    "\n",
    "        # Marque os rótulos semelhantes como mesclados\n",
    "        mescla.update(similar_labels)\n",
    "\n",
    "    return conte_mescla\n",
    "\n",
    "\n",
    "conte_mescla = merge_similar_labels(c3000)\n",
    "len(conte_mescla)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d02ad3",
   "metadata": {},
   "source": [
    "## Separando os dados já tratados para visualização no Power BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0113389a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Selecionando apenas 200 \n",
    "conte_mescla = Counter(conte_mescla)\n",
    "dfmerge = conte_mescla.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6a158704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skills</th>\n",
       "      <th>Quantidade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>python</td>\n",
       "      <td>4439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sql</td>\n",
       "      <td>4396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data analyst</td>\n",
       "      <td>3417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>communication</td>\n",
       "      <td>2465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data visualization</td>\n",
       "      <td>2327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Skills  Quantidade\n",
       "0              python        4439\n",
       "1                 sql        4396\n",
       "2        data analyst        3417\n",
       "3       communication        2465\n",
       "4  data visualization        2327"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transformando em dataframe para transformar em .CSV para dashboard no Power BI\n",
    "\n",
    "dfmerge1 = pd.DataFrame(dfmerge)\n",
    "\n",
    "#Renomeando as colunas \n",
    "dfmerge1 = dfmerge1.rename(columns={0:\"Skills\",1:\"Quantidade\"})\n",
    "dfmerge1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e5769f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge1.to_csv(\"Dados merge\", index = False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
